---
published: true
layout: single
title: "서울대 경제통계학 강의 Review - 1부"
category: Statistics
comments: true
toc: true
toc_sticky: true
use_math: true
---

데이터 분석가가 되기 위해 공부를 시작한 지 6개월 쯤 지났다.

공부를 할수록 수리통계적 기반이 튼튼해야 한다는 걸 느낀다.

배운 건 언젠가 까먹기 마련이기 때문에 블로그에 공부했던 내용을 올려두려고 한다.

[KMOOC]( http://www.kmooc.kr/ ) 공개 강좌인 류근관 교수님의 '경제통계학' 강좌를 보고 통계학 관련 내용을 정리한다.

교수님이 정말 이해하기 쉽게 잘 가르치신다. 통계학에 대해 공부하고 싶다면 추천하는 강좌이다.



## 1-1. 통계학이란?

통계학은 자료를 정리/분석해 유용한 정보를 얻기 위한 언어이자 도구이다. 통계학은 표본의 자료를 수집, 정리, 요약하고 나아가 요약된 자료를 토대로 그 자료의 모태가 되는 모집단에 대해 짐작, 추측해 보는 작업을 포함한다.



### 통계학의 분류

- 기술통계학(descriptive statistics) : 자료를 변수 별로 따로따로 또는 관계되는 변수끼리 묶어서 요약
- 추론통계학(inferential statistics) : 정리된 자료에 담긴 의미를 해석하여 미지의 세계에 대해 추론



### 자료의 종류

- 횡단면 자료(cross-sectional data) : 한 시점에서 여러 개체를 관측한 자료
- 시계열 자료(time-series data) : 한 개체를 여러 시점에 걸쳐 관측한 자료
- 패널 자료(panel data) 또는 종적 자료(longitudinal data) : 횡단면과 시계열의 특성을 결합하여 여러 개체를 여러 시점에 걸쳐 관측한 자료



## 1-2. 통계학과 자료

### 변수의 종류

- 양적(quantitative) 변수 : 나이, 가족의 수, 가구소득
- 질적(qualitative) 변수 : 혼인상태, 취업여부 (일반적으로 질적 변수도 통계처리 목적상 수치로 코딩하여 사용함)
- 이산(discrete) 변수 : 가족의 수처럼 2,3,4,... 등의 이산적인 값만을 취함
- 연속(continuous) 변수 : 나이, 가구소득처럼 연속인 값을 취함
  - 컴퓨터를 통해 숫자를 표현하면 이론상 이는 언제나 이산적일 수밖에 없음
  - 현실적으로는 어떠한 연속변수도 이산적으로 근사 시켜 표현할 수밖에 없음
  - 이때 이 근사의 정확도를 얼마로 할 것인가가 문제의 본질임



### 척도의 종류

- 명목척도 (nominal scale) : 척도의 명칭만 의미 있음
  - 결혼 상태에 대한 코드 - {미혼=1, 기혼=2, 이혼=3, 사별=4}
- 순서척도 (ordinal scale) : 명칭 및 순서가 의미를 지님
  - 성적 등급 - {poor=1, fair=2, good=3, very good=4, excellent=5}
- 간격척도 (interval scale) : 명칭, 순서 및 간격이 의미를 지님
  - 온도
- 비율척도 (ratio scale) : 명칭, 순서, 간격 및 배율 모두 의미를 지님 (절대적 원점이 존재)
  - 키, 몸무게, 재산



### 실험 연구 대 경험적 연구

- 실험 연구 : 무작위 배정 혹은 이중 눈가림을 통해 진행한 실험 (여기서 처리를 가한 집단을 처리집단, 처리를 가하지 않은 집단을 통제집단이라고 부른다)
  - 무작위 배정 : 처리집단과 통제집단을 확률에 의해 무작위 배정 (예. 동전 던지기)
  - 이중 눈가림 : 피험자 본인이 처리를 받았는지 안 받았는지 모르게 조치
- 경험적 연구 : 무작위로 통제된 실험에 대한 연구가 아니기 때문에 자료에 편의가 존재할 수 있다. 
  - 혼동요인 : 통제되지 않은 제 3의 요인이 처리 여부와 관련이 있으면서 동시에 처리집단과 통제집단의 반응에 차별적인 영향을 주는 경우, 이러한 제 3의 요인을 혼동요인이라 한다.
  - 심슨의 역설 : 하위집단에서 관찰된 관계는 하위집단들이 결합되었을 때 그 관계가 바뀌어 나타날 수 있다. (<u>혼동요인 통제의 중요성</u>)
  - 혼동요인의 통제 : 보다 동질적인 하위집단을 <u>따로따로 비교함</u>으로써 혼동요인에 대해 통제



- 이중차분법 (difference in difference): 비교의 비교, 즉 차이의 차이를 이용하여 treatment effect가 존재하는지 분석하는 기법
- 회귀불연속 기법 (regression discontinuity): 아주 작은 차이 => 처리집단과 통제집단의 구분 => 두 집단간 통계적으로 의미 있는 결과의 차이 존재하는지 분석 



## 2-1. 평균과 중앙값

- 평균(mean) : 관측치의 총합을 관측치의 개수로 나누어 구한다 (<u>이상치에 영향을 받음</u>)
- 중앙값(median) : 절반 이상의 숫자들이 이 값보다 크거나 같고 동시에 절반 이상의 숫자들이 이 값보다 작거나 같은 수 (히스토그램은 중앙값에서 그 면적이 양분됨)
- 최빈치(mode) : 가장 많이 관찰되는 값 (히스토그램은 최빈치에서 높이가 제일 높다)



### Median Voter Theorem

- 다수결에 의한 투표는 중앙값 투표자가 선호하는 결과를 선택하게 된다.

- 이는 중앙값이 LAD(least absolute deviation)의 해로 얻어진다는 것과 수학적으로 같은 내용이다.
- 이는 유권자의 신호를 일차원 실직선 상에서 표현할 수 있을 때 성립함
- 유권자의 선호가 다차원적이면 성립하지 않음



## 2-2. 표준편차와 자유도

- 제곱근-평균-제곱 (Root Mean Square)

  - <u>계산은 표현의 역순</u>(제곱 후 평균, 최종적으로 제곱근)

  1. 제곱 (S) : 모든 수를 제곱하여 부호를 없앤다.
  2. 평균 (M) : 제곱된 값들의 평균을 구한다.
  3. 제곱근 (R) : 제곱-평균된 값에 제곱근을 취한다.



- 표준편차 : "평균으로부터의 편차들" 의 RMS와 "대략" 비슷하다.
  - 표준편차는 관측치들이 평균으로부터 얼마나 떨어져 있는지 알려준다
- 68-95 법칙
  - 관측치들의 약 68% 정도가 평균으로부터 1 표준편차 이내로 떨어져 있다.
  - 관측치들의 약 95% 정도가 평균으로부터 2 표준편차 이내로 떨어져 있다.



- 자유도 : 합쳐진 값들 중에서 실질적으로 독립인 값들의 개수
  - 표준편차를 계산하는 경우 자유도는 "자료의 개수 - 1" => 표준편차 계산의 대상이 되는 편차들의 합은 0, 편차들의 합이 0이 된다는 하나의 제약조건이 자유도를 1만큼 감소시킨 것이다.



- 측정오차(measurement error) : 관측치와 실제 값의 차이 (관측치 = 실제값 + 측정오차)
- 측정오차의 대략적인 크기는 관측치들의 표준편차를 통해 알 수 있다
- 편의(bias) : 방향성을 갖는 하나의 체계적인 오차 (관측치 = 실제값 + 편의 + 측정오차)
- 이탈값(outlier) : 극단적인 관측치



## 2-3. 정규분포로의 근사

숫자들이 정규분포곡선을 따른다면 자료가 어떤 구간 내에 어느 정도 비율로 분포되어 있는지 쉽게 알 수 있다. 구간을 표준단위로 바꾸고 표준정규분포곡선 아래 대응되는 <u>영역의 넓이를 구하는 과정</u>을 '정규분포로의 근사' 라고 부른다. 



### 정규분포곡선

하나의 이상적인 히스토그램. 하나의 수학적 모형. 개념상 모집단의 분포



- 정규분포의 확률밀도함수 (probability density function)

  <img src="https://i.ibb.co/SwDnqZM/probability-density-funtion.png" alt="probability-density-funtion" border="0">




- 표준정규분포 (standard normal distribution) : 평균이 0이고 표준편차가 1인 정규분포

  <img src="https://i.ibb.co/f2DCrCW/standard-normal-distribution.png" alt="standard-normal-distribution" border="0">



- 정규분포곡선의 68-95-99.7 규칙
  - 표준단위로 -1부터 1까지 영역의 넓이 : 약 68%
  - 표준단위로 -2부터 2까지 영역의 넓이 : 약 95%
  - 표준단위로 -3부터 3까지 역역의 넓이 : 약 99.7%



- 정규분포곡선의 모양
  - 평균을 중심으로 좌우 대칭(symmetric)
  - 종 모양(bell-shaped)
  - 봉우리가 하나(single-peaked)



- 정규분포곡선의 특징
  - 정규분포곡선은 평균과 표준편차에 의해 그 모양이 완벽하게 묘사된다.
  - 즉, 정규분포를 따르는 히스토그램은 중심과 중심 주위로 퍼진 정도 등 두 정보만으로 100% 묘사된다.



### 분위수의 의미와 활용

- 백분위 수(percentile)는 하나의 히스토그램을 100개의 균등한 영역으로 나누는 99개의 경계점 값들이다.
- 제 p 백분위수는 그 값보다 작은 값이 p%, 큰 값이 (100-p)%가 되는 경계값이다.
- <u>많은 히스토그램은 정규분포곡선과 다르다</u>. (평균과 표준편차만으로는 부족하다)
- 이러한 히스토그램을 요약할 때는 백분위수 개념이 유용하다.



### 사분위수

- 백분위수 가운데 25번째, 50번째, 75번째 백분위수를 특별히 제 1사분위수(first quartile), 제 2사분위수(second quartile), 제 3사분위수(third quartile)라 부른다.
- 50번째 백분위수는 제 2사분위수이면서 중앙값(median)이다.
- 사분위수 범위(interquartile range) : 제 3사분위수 - 제 1사분위수
- 다섯 숫자 요약(five number summary) : 최소값, 제 1사분위수, 제 2사분위수, 제 3사분위수, 최대값
  - (최소값, 최대값) 쌍 대신 (제 5백분위수, 제 95백분위수)쌍 또는 (제 1백분위수, 제 99백분위수)쌍을 사용하기도 한다.



## 3-1. 상관관계

- 결합분포(joint distribution) : 두 변수 사이의 상호관계를 보여준다.
- 산포도(scatter plot) : 두 변수 사이의 관계를 살펴보기 위해 산포도를 이용한다.
  - 설명변수는 x로 표기하고 가로축에 표시
  - 피설명변수는 y로 표기하고 세로축에 표시
  - 가로로 보면 대략 95%의 점들이 x평균점을 기준으로 ±2SDx 이내에 위치한다.
  - 세로로 보면 대략 95%의 점들이 y평균점을 기준으로 ±2SDy 이내에 위치한다.
  - x의 평균과 표준편차, y의 평균과 표준편차는 x와 y의 분포를 따로따로 요약한다.



### 상관계수

상관계수는 두 변수간 <u>선형관계의 방향과 강도</u> 측정 (평균과 표준편차가 동일해도 선형관계의 방향과 강도가 다를 수 있기 때문이다.)

<img src="https://i.ibb.co/JjbZgnS/correlation-coefficient.png" alt="correlation-coefficient" border="0">



- 이변량 자료의 요약 통계량
  - x의 평균과 표준편차
  - y의 평균과 표준편차
  - x와 y간 상관계수 (correlation coefficient) : r로 표기



- 상관계수의 특징
  - 범위 : -1  ≤ r  ≤ 1
  - 상관계수 +1 또는 -1 이면 완전상관(perfect correlation)
    - 모든 점들이 정확히 하나의 선 위에 위치
  - 양의 상관관계이면 점의 분포가 우상향
  - 음의 상관관계이면 점의 분포가 우하향
  - 두 변수의 표준편차가 모두 0이면 상관계수를 정의할 수 없음
  - 두 변수 중 어느 한 변수만의 표준편차가 0이면 상관계수는 0
  - 상관계수는 단위를 갖지 않는다. 즉, 측정단위와 독립적으로 정의됨
    - 하나의 변수가 취하는 모든 값에 상수를 더하거나 빼는 변환을 해도 상관계수는 변하지 않는다.
    - 하나의 변수가 취하는 모든 값에 양의 상수를 곱하거나 양의 상수로 나누는 변환을 해도 상관계수는 변하지 않는다.
  - 상관계수는 방향성을 갖지 않음. 즉 x와 y의 상관계수는 y와 x의 상관계수와 같다.



- 상관계수가 유용하지 않은 경우
  - 이탈값(outlier)이 존재하는 경우
  - 두 변수간 관계가 비선형인 경우



## 3-2. 상관관계와 회귀직선

- 변수 변환 : 적절한 변수변환을 통하여 (x,y)간 존재하는 비선형 관계를 (x, ln(x))간 선형관계로 근사시킴



### 상관관계와 실제 관계

- 비율이나 평균의 자료로부터 구한 상관관계는 종종 실제의 관계를 과장
- 지역이나 국가 등 집단의 자료로부터 구한 상관계수는 개개인에게 적용되는 선형관계를 과장할 가능성이 있음
- 상관계수가 곧바로 인과관계는 아니다



## 3-3. 회귀분석

- 회귀분석(regression analysis)은 집단별 평균을 분석하는 통계적 방법
- 집단을 구분하는 분류지표가 한 개인지, 둘 또는 그 이상인지에 따라 단순회귀분석과 중회귀분석으로 나누어진다
- y의 x에 대한 회귀직선은 각각의 x값에 대응하는 y의 평균값을 추정
- x값이 x평균값에서 1SDx 증가할 때 y값은 y평균값에서 r*SDy 증가 (r:상관계수)
- 회귀직선은 <u>평균의 그래프를 하나의 직선</u>으로 근사 시킨 것
- 평균의 그래프가 비선형이면 회귀직선으로의 선형 근사는 부적절



- 평균으로의 회귀 : 확률 오차가 존재하기 때문에 평균으로 회귀한다.

- 회귀오류 : 회귀효과를 무언가 중요한 효과로 착각하는 것(상관관계 != 인과관계)
- 관찰된 점수 = 실제 실력 + 확률 오차



## 4-1. 회귀직선의 오차

- 제곱근-평균-제곱 오차 (RMSE)
  - 실제 값과 예측치의 차이가 어느 정도 될지 알려줌
  - 추정의 표준오차(standard error of estimate) 또는 회귀의 표준오차(standard error of regression)라고도 불림



- 추정오차
  - 실제 몸무게 - 예측된 몸무게
  - 일반적으로 잔차(residual)라고 부른다
  - 전반적인 크기는 제곱근-평균-제곱(RMS) 방식으로 측정한다.



- RMSE의 계산
  - 분모에 표본크기가 아닌 자유도가 사용되었다.
  - 추정오차 계산의 기준은 회귀직선인데 이는 <u>절편과 기울기의 두 추정치에 의해 결정</u>되므로 <u>자유도는 2만큼 감소</u>



- 회귀직선과 RMSE
  - 회귀직선은 x값에 따라 분류된 <u>부분집단 별로 자료의 중심</u>을 알려준다
  - RMSE는 <u>개별 관측치가</u> 그가 속한 준거집단의 <u>평균으로부터 떨어진 정도</u>를 대략적으로 알려준다
  - <u>회귀직선과 RMSE를 알면</u> 평균과 표준편차를 알 때처럼 <u>68-95 법칙을 활용</u>해 볼 수 있다



<img src="https://i.ibb.co/zmwgfrc/image.png" alt="image" border="0">

산포도상의 점들 중 약 68%가 회귀직선으로부터 ±1RMSE만큼 떨어져 있는 두 직선 사이에 있다. 약 95%의 점들은 ±2RMSE만큼 떨어져 있는 두 직선 사이에 존재한다.

 

### 회귀직선의 RMSE와 y의 표준편차

- 일반적으로 '회귀직선의 RMSE < y의 표준편차' 이는 수평선보다 회귀직선이 산포도 상의 점들에 보다 가까이 위치하기 때문이다
- 회귀직선의 RMSE는 대략 √(1-r²) * SDy와 같다. (단, r은 x와 y의 상관계수)



### 상관계수와 회귀직선의 RMSE

- r = 1 인 경우
  - 산포도상의 모든 점들이 하나의 우상향하는 직선 위에 놓임
  - 추정오차는 모두 0, RMSE=0
- r = -1 인 경우
  - 산포도상의 모든 점들이 하나의 우하향하는 직선 위에 놓임
  - 추정오차는 모두 0, RMSE=0
- r = 0 인 경우
  - 두 변수 x와y간에 선형관계가 전혀 없음
  - 회귀직선은 x값으로 부터 y값을 추정하는 데 전혀 도움이 안됨
  - RMSE는 SDy와 대략 같은 값을 갖게 된다.



- 등분산성 : 회귀직선을 중심으로 점들이 위 아래로 퍼진 정도

- 이분산성 : 오차항의 분산이 회귀모형에 포함되는 변수에 따라 일정하지 않게 나타나는 오차항에 있어서의 체계적 패턴현상



## 4-2. 회귀직선

- 절편 : x가 0일 때 y값을 의미

- 기울기 : x가 1만큼 증가할 때 y가 증가하는 정도를 의미



### 기울기 추정치에 대한 해석상의 주의

통제된 실험으로부터 얻은 자료로 해석할 때는 추정된 기울기를 '외부개입 - 내부반응'으로 해석 가능하나, 경험적 연구로 얻은 기울기면 꼭 그런 것은 아니다.



- 최소자승직선 : 모든 직선 중에서 x를 통해 y를 추정할 때 발생하는 추정오차들의 "제곱의 합"으로 측정한 전반적 크기를 가장 작게 만들어주는 직선
  - 산포도상의 각각의 점으로부터 하나의 직선까지의 수직거리를 정의
  - 수직거리의 "제곱 합"이 최소화 되는 직선을 회귀직선으로 선택
  - 수직거리의 제곱합을 최소화하는 것이나 RMS로 측정한 수직거리의 전반적 크기를 최소화하는 것이나 수학적으로 동일한 최적화 문제임
  - 즉, 최소자승법은 모든 직선 가운데 수직거리의 전반적 크기를 최소화 해주는 직선을 구하는 방법임



- 중회귀분석 : 종종 제3의 변수가 두 변수 x와 y 각각에 영향을 미쳐, 관심의 대상인 두 변수 상호간의 순수한 관계를 왜곡시키게 됨. <u>제3의 변수를 통제할 필요성</u> 대두



## 4-3. 중회귀분석의 응용

<img src="https://i.ibb.co/5WWC418/image.png" alt="image" border="0">

- SST(총 제곱합) : y의 평균 주위로의 총변동
- SSR(회귀제곱합) : 회귀직선에 의해 설명되는 변동분
- SSE(잔차제곱합 or 오차제곱합) : 회귀직선에 의해 설명되지 않는 변동분