---
published: true
layout: single
title: "통계학 정리 (3)"
category: Statistics
comments: true
toc: true
toc_sticky: true
---

포스팅을 하면서 복습을하게 되어서 좋은 것 같다.

1부가 기술통계학에 관련한 내용이었다면, 2부는 추론통계학에 관련한 내용이 나온다.

2부는 예시를 드는 경우가 많아서 꼭 영상으로 직접 보길 추천한다.

아직 3부 강좌를 못 들어서 2부 포스팅 완료하고 남은 3부 강좌도 수강할 예정이다.

<br/>

# 1. 확률이란 무엇인가?

**확률을 보는 두 가지 견해**

- 도수이론 : 확률은 한 시행을 동일한 조건 하에서 독립적으로 반복할 때 그 사건이 일어날 것으로 예측되는 횟수의 전체 시행횟수에 대한 백분율이다.
- 주관적 견해 : 사건에 대한 주관적 확신의 정도가 확률이다. 이는 반복시행 여부와 관계없이 정의된다.

<br/>

**확률의 특성**

확률은 0% 부터 100% 사이의 값을 가진다. (어떤 사건 A가 일어날 확률이 P(A)이면 그 사건이 일어나지 않을 확률은 1-P(A)이다.)

<br/>

**복원추출과 비복원추출**

<img src="https://i.ibb.co/KbMRWk6/image.png" alt="image" border="0">

<br/>

**덧셈법칙**

P(A or B), P(A 그리고 B)
- 두 사건 중 적어도 하나의 사건이 일어날 확률

P(A and B), P(A 또는 B)

- 두 사건이 함께 일어날 확률

덧셈법칙 (<u>두 가지 사건의 합으로 생각할 수 있다.</u>)

- P(A or B) = P(A) + P(B) - P(A and B)

<br/>

**곱셈 법칙**

두 사건이 모두 일어날 확률은 '하나의 사건이 일어날 확률'과 '하나의 사건이 일어났다는 조건 하에서 다른 하나의 사건이 일어날 조건부확률'을 곱하여 얻는다.

<p align="center">P(A and B) = P(A)ㆍP(B|A) = P(B)ㆍP(A|B)</p>

<br/>
P(A and B): 결합확률 (joint probability)

- 두 사건이 함께 일어날 확률

P(A│B): 조건부확률 (conditional probability)

- 사건 B가 주어진 조건 하에서 사건 A가 일어날 확률

P(A), P(B): 주변확률 (marginal probability)

- 비조건부 확률

<br/>

<u>Point : 모든 확률은 덧셈법칙과 곱셈법칙으로 표현 가능하다</u>

<br/>

**독립**

하나의 사건이 일어나느냐 마느냐와 상관없이 다른 사건이 일어날 확률이 변하지 않으면, 두 사건의 관계가 독립(independent)이라고 한다. 그렇지 않은 경우 두 사건의 관계가 종속(dependent)이라고 한다.

- 복원추출일 경우에는 매번의 추출이 독립이고, 비복원추출일 경우에는 종속이다.

두 사건이 서로 독립일 때, 두 사건이 모두 일어날 확률은 각각의 비조건부 확률을 곱하여 얻는다. 이를 <u>좁은 의미의 곱셈법칙</u>이라고 부른다.

- 두 사건 A와 B가 독립이면, P(A and B) = P(A)P(B)

<br/>

**배반과 독립, 덧셈과 곱셈**

- 상호배반 : 하나의 사건이 발생하면 다른 사건이 발생할 수 없는 경우
- 상호독립 : 하나의 사건이 발생하든 말든 다른 사건이 일어날 확률이 변하지 않는 경우
- 상호배반인 두 사건은 서로 종속이다.
  - 두 사건 A, B가 상호배반이면 사건 A가 일어나는 경우 사건 B가 일어날 확률은 0으로 변경된다. 즉, 상호배반이면 독립일 수 없다.

<br/>

- 덧셈법칙
  - 두 사건 중 적어도 하나의 사건이 일어날 확률과 관련
  - 좁은 의미의 덧셈법칙은 상호배반일 경우만 가능
  - 배반이 아닌 경우 중복 계산되는 부분을 제거해야 한다.
- 곱셈법칙
  - 두 사건이 함께 일어날 확률과 관련
  - 좁은 의미의 곱셈법칙은 상호독립일 경우만 가능
  - 독립이 아닌 (종속의) 경우 하나의 주변확률과 다른 하나의 조건부확률을 곱해야 한다.

<br/>

**분할**

합쳐서 전체를 포괄하되 겹쳐서 전혀 중복이 안 되는 사건들의 집합

<img src="https://i.ibb.co/V3jPFQk/image.png" alt="image" border="0">

<br/>

**조건부확률**

P(A│B) : 조건부확률

- 사건 B가 주어진 조건 하에서 사건 A가 일어날 확률
- 사건 B에만 포커스를 맞춤
- 사건 B의 확률에 대한 사건 A와 B 결합사건 확률의 상대적 크기

<img src="https://i.ibb.co/HBnpssW/image.png" alt="image" border="0">

<br/>

**베이즈 정리의 본질**

베이즈 정리의 본질은 <u>"입장을 바꿔 생각"</u> 함으로써 미지의 세계에 대해 추론하는 것이다.

<br/>
$$
P(A|B) = {P(A)P(B|A) \over P(A)P(B|A) + P(A^c)P(B|A^c)}
$$

<br/>

# 2. 이항공식

- 베르누이 시행 : 합격/불합격, 성공/실패처럼 결과가 둘로 나뉘는 시행
- 베르누이 확률변수 : 베르누이 시행에서 성공에 1을, 실패에 0을 대응시키는 확률변수

<br/>

**이항확률변수, 이항분포**

- 성공확률이 p로 일정한 베르누이 시행을 독립적으로 n번 반복
- X1, X2, ... , Xn은 각각 첫 번째, 두 번째, ... , n 번째 시행의 결과
- X = 총 성공횟수 = 이항확률변수
- X = X1 + X2 + X3 + ... + Xn으로 표현됨
- X ~ B(n, p) : X는 n과 p를 모수로 갖는 이항분포를 따름

<br/>

**표로 정리**

| 구분                     | n = 1                        | 일반적인 경우                             |
| :----------------------- | ---------------------------- | ----------------------------------------- |
| 확률변수                 | X1                           | X = X1 + X2 + ... + Xn                    |
| 명칭                     | 베르누이 확률변수            | 이항 확률변수                             |
| 분포                     | 베르누이 확률분포            | 이항 확률분포                             |
| Central tendency(기댓값) | E(X1) = P                    | E(X) = E(X1 + ... + Xn) = nP              |
| RMSE                     | SD(X1) = √E(X1-P)² = √P(1-P) | SE(X) = √E(X-E(X))² = √np(1-p)=√nㆍSD(X1) |

<br/>

<u>Point : n이 1개 일때는 Standard Deviation 이라 쓰고, n이 여러개 일때는 Standard Error라고 쓴다.</u>

<br/>

**이항공식**

n번의 시행 중 k번 성공할 확률

<br/>
$$
P(X=k)={n! \over k!(n-k)!}p^k(1-p)^{n-k}, k=0,1,...,n
$$
<br/>

여기서 n은 시행횟수, k는 성공횟수, p는 성공확률을 나타냄

<br/>

이항공식은 다음 조건하에서 성립한다.

- n의 값은 미리 정해져 있다.
- 매 번의 시행은 상호 독립이다.
- p는 매 시행마다 동일하다.

<br/>

# 3. 평균의 법칙

**평균의 법칙**

- 동전을 던졌을 때 이미 앞면이 많이 나왔다고 해서 이후의 시행에서 앞면이 나올 확률이 감소하는 것은 아니다. 

- 던지는 횟수가 증가한다고 해서 앞면이 나오는 횟수와 기대횟수의 차이가 줄어드는 것도 아니다.

- 시행횟수가 증가할수록 확률오차의 절대적 크기는 증가한다.

- 시행횟수가 증가할수록 <u>시행횟수에 대비한 확률오차의 상대적 크기는 감소</u>한다. (=평균의법칙)

<br/>

**확률과정**

- 동전던지기에서 앞면이 나오는 횟수를 기록하는 일
- 카지노 룰렛 게임에서 몇 번 이길지 계산해보는 일
- 표본조사를 통해 구한 실업률의 정확도를 측정하는 일
- 선거결과를 예측하기 위한 여론조사 결과를 해석하는 일

<br/>

- 상자모형 : 하나의 확률과정을 상자에서 숫자를 무작위로 추출하는 과정으로 묘사. 상자모형을 이용할 경우 복잡한 확률과정도 쉽게 이해됨
- 추론 : 표본정보를 이용하여 모집단에 대해 무언가를 알아내는 과정. (모집단=상자)

<br/>

# 4. 기대값과 표준오차

- 기대값 : 하나의 확률 과정에 의해 결정되는 숫자는 하나의 값 주위로 분포한다. 이때 기대값은 <u>분포의 무게 중심</u>에 해당되는 값이다.

<p align="center">합의 기대값 = 추출회수 x 상자의 평균</p>


- 표준오차 : <u>실현된 값이 기대값과 차이가 나는 정도</u>는 표준오차에 의해 측정된다.
  - 확률과정에 의해 결정되는 숫자는 기대값 주위로 분포하며, 기대값과 표준오차정도 차이가 나는 경향이 있다.

<p align="center">추출한 숫자들의 합 = 합의 기대값 + 합에 든 확률오차</p>

<br/>

**제곱근법칙**

상자에서 무작위 복원 추출할 경우 합의 표준오차 계산 (추출회수가 1인 경우 합의 표준오차는 바로 상자의 표준편차와 같다.)

<p align="center">합의 표준오차 = 상자의 표준편차 x 추출회수<sup>1/2</sup></p>


- 상자의 표준편차 : 상자 안에 든 숫자들이 서로 다른 정도를 나타냄. 상자 안에 든 숫자들이 서로 다를수록 예측하기 어렵다. → 표준편차가 커지면 표준오차도 커진다.
- 추출회수 : 상자로부터 카드를 뽑을 때 어떤 숫자를 뽑을지 알 수 없기 때문에, 추출회수를 늘리면 그 합을 예측하기는 점점 더 어려워진다. 그러나 그 난이도가 추출회수에 비례하여 증가하지는 않는다. 난이도를 측정하는 <u>표준오차는 추출회수의 제곱근에 비례하여 증가한다.</u>

<br/>

- 오차의 절대적 크기는 횟수의 제곱근으로 곱해져 증가함
- 오차의 상대적 크기(비율)는 횟수의 제곱근으로 나누어져 감소함

<br/>

# 5. 정규분포곡선과 확률히스토그램

- 합의 경험적 히스토그램 : 여러 차례 반복적으로 관측한 합의 자료를 구간별로 분류하고 구간별 도수를 계산한 뒤 도수를 밀도단위로 바꾸어 밀도단위 히스토그램으로 나타낸 것
- 합의 확률히스토그램 : 상자의 내용물 및 추출횟수로부터 합이 각각의 값으로 실현될 확률을 계산하여 이를 그래프로 나타낸 것

<br/>

**경험적 히스토그램과 확률히스토그램**

두 개 주사위를 던지는 실험을 반복하여 합에 대해 얻어낸 경험적 자료를 가지고 합의 히스토그램을 그리면 반복하는 횟수가 증가함에 따라 경험적 히스토그램은 확률 히스토그램으로 수렴하게 된다.

<img src="https://i.ibb.co/wMg4CPK/image.png" alt="image" border="0">

<br/>

**중심극한정리(CLT: Central Limit Theorem)**

상자로부터 무작위로 복원추출할 때 추출횟수가 증가함에 따라 합 또는 평균의 확률히스토그램은 정규분포곡선으로 수렴해간다.

- 중심극한정리는 일반적으로 상자의 내용물에 관계없이 성립한다.
- 다만, 확률히스토그램을 정규분포곡선으로 근사시킬 때 근사에 필요한 최소한의 추출횟수는 달라진다.
- 상자의 내용물 분포가 정규분포곡선과 비슷하면 비슷할수록 추출횟수가 적어도 정규분포로 근사가 잘 되나 그렇지 않으면 추출횟수가 많아야 한다.

- 중심극한정리는 곱에 대해서는 성립하지 않는다.
  - 곱의 히스토그램은 정규분포곡선과 다르다.
  - 곱의 분포는 합의 분포와 모양이 아주 다르다.

<br/>

**평균의 법칙과 중심극한정리**

| 수렴의 조건 | 반복시행의 횟수가 무한히 증가 | 추출 횟수가 무한히 증가 |
| ----------- | ----------------------------- | ----------------------- |
| 관련된 법칙 | 평균의 법칙(=대수의 법칙)     | 중심극한정리            |

<br/>

**부트스트래핑**

표본 크기도 크지 않고 마땅히 이론의 도움도 기대할 수 없는 상황에서 표본합이나 평균의 확률히스토그램을 주어진 자료만을 가지고 근사시키는 방법

- 추출횟수가 적을 때 표본합 내지 표본평균의 확률히스토그램을 무작정 정규분포로 근사시키는 것은 위험
- 이러한 경우 표본합 내지 표본평균의 확률히스토그램, 즉 표본분포를 근사시키기 위한 현실적 대안 중 하나가 부트스트래핑